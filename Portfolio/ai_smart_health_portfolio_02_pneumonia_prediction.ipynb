{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7df7b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5180d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c01f4ef",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "Similar to former notebooks where we worked with the [ChestX-ray8 dataset](https://arxiv.org/abs/1705.02315), where here have a smaller X-ray dataset containing 5856 images.\n",
    "Instead of 14 different diseases we will here concentrate on much fewer possible labels so that *hopefully* the number of images is enough to train good deep learning classifiers.\n",
    "\n",
    "The images are distributed accross two folders (`NORMAL` and `PNEUMONIA`), the related metadata can be found in `x_ray_metadata_portfolio.csv` but actually also is reflected in the image file names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01021945",
   "metadata": {},
   "source": [
    "## Import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "953f519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/ChestXray_pneumonia_prediction/\"\n",
    "csv_file = 'x_ray_metadata_portfolio.csv'\n",
    "metadata = pd.read_csv(path + csv_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08a4be7d",
   "metadata": {},
   "source": [
    "# Portfolio exercises:\n",
    "### 1. load and inspect the data \n",
    "- what are missing/problematic entries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "15b0b0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "      <th>infection_type</th>\n",
       "      <th>folder</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0001-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0003-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0005-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0006-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0007-0001.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id   label infection_type  folder              image\n",
       "0       0001  normal           none  NORMAL  IM-0001-0001.jpeg\n",
       "1       0003  normal           none  NORMAL  IM-0003-0001.jpeg\n",
       "2       0005  normal           none  NORMAL  IM-0005-0001.jpeg\n",
       "3       0006  normal           none  NORMAL  IM-0006-0001.jpeg\n",
       "4       0007  normal           none  NORMAL  IM-0007-0001.jpeg"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cf640e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5856 entries, 0 to 5855\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   patient_id      5856 non-null   object\n",
      " 1   label           5856 non-null   object\n",
      " 2   infection_type  5856 non-null   object\n",
      " 3   folder          5856 non-null   object\n",
      " 4   image           5856 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 228.9+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "367176f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id        0\n",
       "label             0\n",
       "infection_type    0\n",
       "folder            0\n",
       "image             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db080bbb",
   "metadata": {},
   "source": [
    "Luckily there are no null values in our data and we can use it without deleting any entries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79921bec",
   "metadata": {},
   "source": [
    "### 2. data exploration and cleaning \n",
    "- remove, fill, change data (if you think this makes sense or is necessary/beneficial)\n",
    "- inspect two different types of labels (`label` and `infection_type`). How many classes are there and is there any bias? If so, is there anything we have to take care of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "226343ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bacteria    2780\n",
       "none        1583\n",
       "virus       1493\n",
       "Name: infection_type, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['infection_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "257a7202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pneumonia    4273\n",
       "normal       1583\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd423ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6993051168667086"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.loc[metadata['label'] == 'pneumonia'].__len__() / metadata.loc[metadata['label'] == 'normal'].__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dede81c0",
   "metadata": {},
   "source": [
    "There are 3 infection types: bacteria, virus and none. There are roughly as many viral infections as there are healthy patients. But the amount of bacterial infections is almost double the size of the other two cases.\n",
    "Also if we just look at the label column the data is heavily biased towards the diseased patients, which is 2.7 times as much.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1d9a3a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 patients with pneumonia, that have no bacterial or viral infection\n"
     ]
    }
   ],
   "source": [
    "# check if all infected are also diseased\n",
    "counter = 0\n",
    "for index, row in metadata.iterrows():\n",
    "    if(row[\"infection_type\"] == \"none\" and row['label'] == 'pneumonia'):\n",
    "         counter+=1\n",
    "         \n",
    "print(\"There are {} patients with pneumonia, that have no bacterial or viral infection\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0d48375b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PNEUMONIA    4273\n",
       "NORMAL       1583\n",
       "Name: folder, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['folder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "82e02e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all pictures are in the right folder\n",
    "for index, row in metadata.iterrows():\n",
    "    if row['folder'].lower() != row['label']:\n",
    "        print('Error in row: ', index)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "83bee610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person23      31\n",
       "person124     20\n",
       "person441     18\n",
       "person30      15\n",
       "person1320    14\n",
       "              ..\n",
       "person1580     1\n",
       "0907           1\n",
       "person1579     1\n",
       "person1577     1\n",
       "0001           1\n",
       "Name: patient_id, Length: 2790, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['patient_id'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2191efca",
   "metadata": {},
   "source": [
    "It is also noteworthy that some patients are presented multiple times in the dataset, while others have only a single entry."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16dc19f3",
   "metadata": {},
   "source": [
    "### 3. Prepare data for machine learning: \n",
    "- Separate data / labels\n",
    "- Split into train ~70% / validation ~15% / test ~15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "87daf1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "      <th>infection_type</th>\n",
       "      <th>folder</th>\n",
       "      <th>image</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>person276</td>\n",
       "      <td>1</td>\n",
       "      <td>bacteria</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>person276_bacteria_1297.jpeg</td>\n",
       "      <td>PNEUMONIA/person276_bacteria_1297.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>person403</td>\n",
       "      <td>1</td>\n",
       "      <td>virus</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>person403_virus_803.jpeg</td>\n",
       "      <td>PNEUMONIA/person403_virus_803.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0553</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL2-IM-0553-0001.jpeg</td>\n",
       "      <td>NORMAL/NORMAL2-IM-0553-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0031</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0031-0001.jpeg</td>\n",
       "      <td>NORMAL/IM-0031-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0353</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL2-IM-0353-0001.jpeg</td>\n",
       "      <td>NORMAL/NORMAL2-IM-0353-0001.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id  label infection_type     folder  \\\n",
       "3649  person276      1       bacteria  PNEUMONIA   \n",
       "4211  person403      1          virus  PNEUMONIA   \n",
       "960        0553      0           none     NORMAL   \n",
       "23         0031      0           none     NORMAL   \n",
       "810        0353      0           none     NORMAL   \n",
       "\n",
       "                             image                                filepath  \n",
       "3649  person276_bacteria_1297.jpeg  PNEUMONIA/person276_bacteria_1297.jpeg  \n",
       "4211      person403_virus_803.jpeg      PNEUMONIA/person403_virus_803.jpeg  \n",
       "960      NORMAL2-IM-0553-0001.jpeg        NORMAL/NORMAL2-IM-0553-0001.jpeg  \n",
       "23               IM-0031-0001.jpeg                NORMAL/IM-0031-0001.jpeg  \n",
       "810      NORMAL2-IM-0353-0001.jpeg        NORMAL/NORMAL2-IM-0353-0001.jpeg  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle data\n",
    "shuffled_data = metadata.sample(frac=1, random_state=42)\n",
    "\n",
    "# combine folder and image file name to file path\n",
    "for index, row in shuffled_data.iterrows():\n",
    "    shuffled_data.at[index, 'filepath'] = \"{}/{}\".format(row['folder'], row['image'])\n",
    "    if(row['label'] == 'pneumonia'):\n",
    "        row['label'] = 1\n",
    "    else:\n",
    "        row['label'] = 0\n",
    "\n",
    "shuffled_data['label'] = shuffled_data['label'].astype(np.int32)\n",
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "93076ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 6) (879, 6) (4099, 6)\n",
      "Train data share:  0.6999658469945356\n",
      "Test data share:  0.14993169398907105\n",
      "Validation data share:  0.15010245901639344\n"
     ]
    }
   ],
   "source": [
    "# split train and test data into 70% and 30% respectively\n",
    "train_df, test_df = train_test_split(shuffled_data, test_size=0.3, random_state=42)\n",
    "# split the 30% test data into 15% and 15% for validation and test respectively\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# check the distribution after the split\n",
    "print(test_df.shape, val_df.shape, train_df.shape)\n",
    "\n",
    "print(\"Train data share: \", train_df.shape[0] / shuffled_data.shape[0])\n",
    "print(\"Test data share: \", test_df.shape[0] / shuffled_data.shape[0])\n",
    "print(\"Validation data share: \", val_df.shape[0]/ shuffled_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3df9bc4",
   "metadata": {},
   "source": [
    "### 4. Build an image generator pipeline\n",
    "- Use keras `ImageDataGenerator` to define a `train_generator` and a `validation_generator`.\n",
    "- Use the generator to recale the pixel values and to reshape the image to the desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ea319d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4099 validated image filenames.\n",
      "Found 879 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Normalize images\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")\n",
    "\n",
    "# Pick your label column(s)\n",
    "label_column = ['N', 'D', 'G', 'C', 'A', 'H', 'M',] # add the label-columns we want to predict\n",
    "\n",
    "# Define the data generators\n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=path,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(320, 320),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"rgb\" # add color mode\n",
    ")\n",
    "\n",
    "val_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=path,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(320, 320),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"rgb\", #add color mode,\n",
    "    shuffle=False,  # this is crucial for later evaluation!\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a384786",
   "metadata": {},
   "source": [
    "### 5. Train your own custom-made CNN (pneumonia yes/no prediction)\n",
    "- Define a conventional CNN image classifier (convolution-pooling steps, followed by dense layers) to predict if a patient has pneumonia or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bee3b272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 320, 320, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 318, 318, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 159, 159, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 157, 157, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 78, 78, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 76, 76, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 38, 38, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 36, 36, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 18, 18, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                524352    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 912,833\n",
      "Trainable params: 912,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Define the input shape\n",
    "inputs = Input(shape=(320, 320, 3))\n",
    "\n",
    "# Define the CNN architecture\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)#add code here, activation=#add code here)(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "00472659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=\"accuracy\") #metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0449ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/129 [..............................] - ETA: 10:00 - loss: 0.6388 - accuracy: 0.5781"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      3\u001b[0m     train_generator,\n\u001b[0;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_generator,\n\u001b[0;32m      6\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\anaconda3\\envs\\ai4sh\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d8a5077",
   "metadata": {},
   "source": [
    "### 6. Use transfer learning to train a CNN classifier (pneumonia yes/no prediction)\n",
    "- Pick any suitable CNN you like (e.g. Resnet-50, Densenet, MobileNet...) and create your own image classifier from there."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c06d4357",
   "metadata": {},
   "source": [
    "### 7. Evaluate both models\n",
    "- Evaluate the models on data other than the training data.\n",
    "- Plot a ROC curve and compute the area under the curve (AUC). What does this tell you?\n",
    "- Compare to your custom-made CNN: which one achieves better results (and why)? Which one trains faster (and why)? What would you prefer to use in an actual medical application?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20189d53",
   "metadata": {},
   "source": [
    "### 8. Train a CNN for a multi-class prediction (bacteria, virus, none)\n",
    "- Adapt a CNN (e.g. pick one form 5. or 6.) and modify it to predict if a patient has a bacterial or a virus infection, or none of both using the `infection_type` column as label.\n",
    "- This requires to also adapt the generators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d16a92c",
   "metadata": {},
   "source": [
    "### 9. Evaluate the multi-class model\n",
    "- Evaluate the multi-class prediction model, simliar to what you did in (7.). Again also include a ROC curve (now of course for all 3 possible labels).\n",
    "- Is the performance comparable, better, worse than the pneumonia/no pneumonia case?\n",
    "- Which label can be predicted with the highest precision?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f30c402b",
   "metadata": {},
   "source": [
    "### 10. Possible improvements\n",
    "Try two possible strategies to improve the results you got on 8. and 9.\n",
    "- Data augmentation.\n",
    "- Model fine tuning. This refers to the training of a large network with lower learning rate, but with more layers of the base model being set to `trainable`.\n",
    "We haven't done this before, so here some example code of how to \"unfreeze\" some layers and make them trainable again:\n",
    "```python\n",
    "# Now: unfreeze some of the base model layers and do a second pass of training\n",
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True\n",
    "``` \n",
    "You can still use the `Adam` optimizer, but preferably with a much lower learning rate, maybe `1e-5`.\n",
    "- Do you see any promising effect of one or both of those strategies?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc5554fa",
   "metadata": {},
   "source": [
    "## Final submission:\n",
    "Please address all the above mentioned points in this notebook (e.g., using text cells where needed for explanations or answers). Obviously, you can use code snippets from notebooks we have already worked on during the live coding sessions.\n",
    "\n",
    "\n",
    "### Happy hacking!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
