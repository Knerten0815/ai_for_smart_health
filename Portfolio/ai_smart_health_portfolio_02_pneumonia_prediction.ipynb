{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df7b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 16:37:17.023026: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001cd74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-29 16:37:37.715966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-29 16:37:38.055239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-06-29 16:37:38.055734: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5180d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c01f4ef",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "Similar to former notebooks where we worked with the [ChestX-ray8 dataset](https://arxiv.org/abs/1705.02315), where here have a smaller X-ray dataset containing 5856 images.\n",
    "Instead of 14 different diseases we will here concentrate on much fewer possible labels so that *hopefully* the number of images is enough to train good deep learning classifiers.\n",
    "\n",
    "The images are distributed accross two folders (`NORMAL` and `PNEUMONIA`), the related metadata can be found in `x_ray_metadata_portfolio.csv` but actually also is reflected in the image file names."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01021945",
   "metadata": {},
   "source": [
    "## Import metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953f519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/ChestXray_pneumonia_prediction/\"\n",
    "csv_file = 'x_ray_metadata_portfolio.csv'\n",
    "metadata = pd.read_csv(path + csv_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08a4be7d",
   "metadata": {},
   "source": [
    "# Portfolio exercises:\n",
    "### 1. load and inspect the data \n",
    "- what are missing/problematic entries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b0b0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "      <th>infection_type</th>\n",
       "      <th>folder</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0001-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0003-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0005</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0005-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0006</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0006-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007</td>\n",
       "      <td>normal</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0007-0001.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id   label infection_type  folder              image\n",
       "0       0001  normal           none  NORMAL  IM-0001-0001.jpeg\n",
       "1       0003  normal           none  NORMAL  IM-0003-0001.jpeg\n",
       "2       0005  normal           none  NORMAL  IM-0005-0001.jpeg\n",
       "3       0006  normal           none  NORMAL  IM-0006-0001.jpeg\n",
       "4       0007  normal           none  NORMAL  IM-0007-0001.jpeg"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf640e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5856 entries, 0 to 5855\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   patient_id      5856 non-null   object\n",
      " 1   label           5856 non-null   object\n",
      " 2   infection_type  5856 non-null   object\n",
      " 3   folder          5856 non-null   object\n",
      " 4   image           5856 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 228.9+ KB\n"
     ]
    }
   ],
   "source": [
    "metadata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367176f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id        0\n",
       "label             0\n",
       "infection_type    0\n",
       "folder            0\n",
       "image             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db080bbb",
   "metadata": {},
   "source": [
    "Luckily there are no null values in our data and we can use it without deleting any entries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79921bec",
   "metadata": {},
   "source": [
    "### 2. data exploration and cleaning \n",
    "- remove, fill, change data (if you think this makes sense or is necessary/beneficial)\n",
    "- inspect two different types of labels (`label` and `infection_type`). How many classes are there and is there any bias? If so, is there anything we have to take care of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226343ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "infection_type\n",
       "bacteria    2780\n",
       "none        1583\n",
       "virus       1493\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['infection_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257a7202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "pneumonia    4273\n",
       "normal       1583\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd423ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6993051168667086"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.loc[metadata['label'] == 'pneumonia'].__len__() / metadata.loc[metadata['label'] == 'normal'].__len__()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dede81c0",
   "metadata": {},
   "source": [
    "There are 3 infection types: bacteria, virus and none. There are roughly as many viral infections as there are healthy patients. But the amount of bacterial infections is almost double the size of the other two cases.\n",
    "Also if we just look at the label column the data is heavily biased towards the diseased patients, which is 2.7 times as much.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d9a3a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 patients with pneumonia, that have no bacterial or viral infection\n"
     ]
    }
   ],
   "source": [
    "# check if all infected are also diseased\n",
    "counter = 0\n",
    "for index, row in metadata.iterrows():\n",
    "    if(row[\"infection_type\"] == \"none\" and row['label'] == 'pneumonia'):\n",
    "         counter+=1\n",
    "         \n",
    "print(\"There are {} patients with pneumonia, that have no bacterial or viral infection\".format(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d48375b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "folder\n",
       "PNEUMONIA    4273\n",
       "NORMAL       1583\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['folder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82e02e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all pictures are in the right folder\n",
    "for index, row in metadata.iterrows():\n",
    "    if row['folder'].lower() != row['label']:\n",
    "        print('Error in row: ', index)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83bee610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id\n",
       "person23      31\n",
       "person124     20\n",
       "person441     18\n",
       "person30      15\n",
       "person1320    14\n",
       "              ..\n",
       "person1580     1\n",
       "0907           1\n",
       "person1579     1\n",
       "person1577     1\n",
       "0001           1\n",
       "Name: count, Length: 2790, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['patient_id'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2191efca",
   "metadata": {},
   "source": [
    "It is also noteworthy that some patients are presented multiple times in the dataset, while others have only a single entry."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16dc19f3",
   "metadata": {},
   "source": [
    "### 3. Prepare data for machine learning: \n",
    "- Separate data / labels\n",
    "- Split into train ~70% / validation ~15% / test ~15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87daf1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>label</th>\n",
       "      <th>infection_type</th>\n",
       "      <th>folder</th>\n",
       "      <th>image</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>person276</td>\n",
       "      <td>1</td>\n",
       "      <td>bacteria</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>person276_bacteria_1297.jpeg</td>\n",
       "      <td>PNEUMONIA/person276_bacteria_1297.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>person403</td>\n",
       "      <td>1</td>\n",
       "      <td>virus</td>\n",
       "      <td>PNEUMONIA</td>\n",
       "      <td>person403_virus_803.jpeg</td>\n",
       "      <td>PNEUMONIA/person403_virus_803.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>0553</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL2-IM-0553-0001.jpeg</td>\n",
       "      <td>NORMAL/NORMAL2-IM-0553-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0031</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>IM-0031-0001.jpeg</td>\n",
       "      <td>NORMAL/IM-0031-0001.jpeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0353</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NORMAL2-IM-0353-0001.jpeg</td>\n",
       "      <td>NORMAL/NORMAL2-IM-0353-0001.jpeg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id  label infection_type     folder   \n",
       "3649  person276      1       bacteria  PNEUMONIA  \\\n",
       "4211  person403      1          virus  PNEUMONIA   \n",
       "960        0553      0           none     NORMAL   \n",
       "23         0031      0           none     NORMAL   \n",
       "810        0353      0           none     NORMAL   \n",
       "\n",
       "                             image                                filepath  \n",
       "3649  person276_bacteria_1297.jpeg  PNEUMONIA/person276_bacteria_1297.jpeg  \n",
       "4211      person403_virus_803.jpeg      PNEUMONIA/person403_virus_803.jpeg  \n",
       "960      NORMAL2-IM-0553-0001.jpeg        NORMAL/NORMAL2-IM-0553-0001.jpeg  \n",
       "23               IM-0031-0001.jpeg                NORMAL/IM-0031-0001.jpeg  \n",
       "810      NORMAL2-IM-0353-0001.jpeg        NORMAL/NORMAL2-IM-0353-0001.jpeg  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle data\n",
    "shuffled_data = metadata.sample(frac=1, random_state=42)\n",
    "\n",
    "# combine folder and image file name to file path\n",
    "for index, row in shuffled_data.iterrows():\n",
    "    shuffled_data.at[index, 'filepath'] = \"{}/{}\".format(row['folder'], row['image'])\n",
    "    if(row['label'] == 'pneumonia'):\n",
    "        row['label'] = 1\n",
    "    else:\n",
    "        row['label'] = 0\n",
    "\n",
    "shuffled_data['label'] = shuffled_data['label'].astype(np.int32)\n",
    "shuffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93076ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878, 6) (879, 6) (4099, 6)\n",
      "Train data share:  0.6999658469945356\n",
      "Test data share:  0.14993169398907105\n",
      "Validation data share:  0.15010245901639344\n"
     ]
    }
   ],
   "source": [
    "# split train and test data into 70% and 30% respectively\n",
    "train_df, test_df = train_test_split(shuffled_data, test_size=0.3, random_state=42)\n",
    "# split the 30% test data into 15% and 15% for validation and test respectively\n",
    "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# check the distribution after the split\n",
    "print(test_df.shape, val_df.shape, train_df.shape)\n",
    "\n",
    "print(\"Train data share: \", train_df.shape[0] / shuffled_data.shape[0])\n",
    "print(\"Test data share: \", test_df.shape[0] / shuffled_data.shape[0])\n",
    "print(\"Validation data share: \", val_df.shape[0]/ shuffled_data.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3df9bc4",
   "metadata": {},
   "source": [
    "### 4. Build an image generator pipeline\n",
    "- Use keras `ImageDataGenerator` to define a `train_generator` and a `validation_generator`.\n",
    "- Use the generator to recale the pixel values and to reshape the image to the desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea319d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4099 validated image filenames.\n",
      "Found 879 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Normalize images\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")\n",
    "\n",
    "# Pick your label column(s)\n",
    "label_column = ['N', 'D', 'G', 'C', 'A', 'H', 'M',] # add the label-columns we want to predict\n",
    "\n",
    "# Define the data generators\n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=path,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(320, 320),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"rgb\" # add color mode\n",
    ")\n",
    "\n",
    "val_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=path,\n",
    "    x_col=\"filepath\",\n",
    "    y_col=\"label\",\n",
    "    target_size=(320, 320),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"rgb\", #add color mode,\n",
    "    shuffle=False,  # this is crucial for later evaluation!\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a384786",
   "metadata": {},
   "source": [
    "### 5. Train your own custom-made CNN (pneumonia yes/no prediction)\n",
    "- Define a conventional CNN image classifier (convolution-pooling steps, followed by dense layers) to predict if a patient has pneumonia or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Define the input shape\n",
    "inputs = Input(shape=(320, 320, 3))\n",
    "\n",
    "# Define the CNN architecture\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)#add code here, activation=#add code here)(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00472659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=\"accuracy\") #metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f0d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model checkpoints\n",
    "checkpoint_path = \"model_checkpoints/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,    # saving only the weights, because we have the architecture of the model\n",
    "                                                 verbose=1, \n",
    "                                                 monitor='val_accuracy',    # we are monitoring the accuracy on the validation set\n",
    "                                                 mode='max',                # the greatest accuracy on the validation is the best outcome\n",
    "                                                 save_best_only=True)       # we only want to save the best model. The other chechpoints are not interesting to us\n",
    "\n",
    "# stop the training when the model is no longer improving its accuracy on the validation set for 3 epochs\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0449ae20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 22:01:24.129481: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 39321600 exceeds 10% of free system memory.\n",
      "2023-06-28 22:01:24.333183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 22:01:30.475649: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 39321600 exceeds 10% of free system memory.\n",
      "2023-06-28 22:01:31.784455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2023-06-28 22:01:34.308784: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 39321600 exceeds 10% of free system memory.\n",
      "2023-06-28 22:01:35.138529: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1000.39MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:35.345371: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 691.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:35.674222: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 882.57MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:35.674487: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 882.57MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:35.746133: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.53GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:36.274352: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 422.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:36.274493: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 422.12MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:36.375472: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:36.644728: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 676.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-28 22:01:37.154321: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa84c35b1e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-28 22:01:37.154453: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce GTX 1050, Compute Capability 6.1\n",
      "2023-06-28 22:01:37.376302: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-06-28 22:01:39.384503: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-06-28 22:01:42.477385: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 564.25MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  1/129 [..............................] - ETA: 51:22 - loss: 0.6874 - accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 22:01:49.717740: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 39321600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/129 [..............................] - ETA: 8:25 - loss: 0.6587 - accuracy: 0.7396 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 22:01:56.924604: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 39321600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.8229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-28 22:04:21.960445: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 217s 2s/step - loss: 0.4210 - accuracy: 0.8229 - val_loss: 0.2088 - val_accuracy: 0.9204\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 166s 1s/step - loss: 0.1846 - accuracy: 0.9312 - val_loss: 0.1730 - val_accuracy: 0.9386\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 195s 2s/step - loss: 0.1501 - accuracy: 0.9439 - val_loss: 0.1578 - val_accuracy: 0.9431\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 180s 1s/step - loss: 0.1334 - accuracy: 0.9495 - val_loss: 0.1463 - val_accuracy: 0.9522\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 139s 1s/step - loss: 0.1270 - accuracy: 0.9527 - val_loss: 0.1528 - val_accuracy: 0.9465\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 134s 1s/step - loss: 0.1133 - accuracy: 0.9588 - val_loss: 0.1360 - val_accuracy: 0.9545\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 123s 954ms/step - loss: 0.1033 - accuracy: 0.9617 - val_loss: 0.1654 - val_accuracy: 0.9556\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 107s 830ms/step - loss: 0.0898 - accuracy: 0.9661 - val_loss: 0.1348 - val_accuracy: 0.9556\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 109s 842ms/step - loss: 0.0930 - accuracy: 0.9656 - val_loss: 0.1424 - val_accuracy: 0.9556\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 119s 924ms/step - loss: 0.0849 - accuracy: 0.9673 - val_loss: 0.1771 - val_accuracy: 0.9454\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],  # Pass callback to training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810be98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e0ed412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_saved/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_saved/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, \"model_saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d1f752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 08:27:52.431013: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-01 08:28:20.125456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:20.679268: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:20.680305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:20.734778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:20.736709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:20.738349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:24.299860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:24.301061: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:24.301092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-01 08:28:24.301607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:02:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-01 08:28:24.303024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1416 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f4bcd88ab80>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"model_saved\")\n",
    "loaded_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d8a5077",
   "metadata": {},
   "source": [
    "### 6. Use transfer learning to train a CNN classifier (pneumonia yes/no prediction)\n",
    "- Pick any suitable CNN you like (e.g. Resnet-50, Densenet, MobileNet...) and create your own image classifier from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the DenseNet121 model but exclude the top layer (classification layer)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(320, 320, 3))\n",
    "\n",
    "# Add your own top layer for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(len(label_column), activation=\"sigmoid\")(x)\n",
    "\n",
    "# complete code here\n",
    "\n",
    "# Create the actual model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c06d4357",
   "metadata": {},
   "source": [
    "### 7. Evaluate both models\n",
    "- Evaluate the models on data other than the training data.\n",
    "- Plot a ROC curve and compute the area under the curve (AUC). What does this tell you?\n",
    "- Compare to your custom-made CNN: which one achieves better results (and why)? Which one trains faster (and why)? What would you prefer to use in an actual medical application?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20189d53",
   "metadata": {},
   "source": [
    "### 8. Train a CNN for a multi-class prediction (bacteria, virus, none)\n",
    "- Adapt a CNN (e.g. pick one form 5. or 6.) and modify it to predict if a patient has a bacterial or a virus infection, or none of both using the `infection_type` column as label.\n",
    "- This requires to also adapt the generators."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d16a92c",
   "metadata": {},
   "source": [
    "### 9. Evaluate the multi-class model\n",
    "- Evaluate the multi-class prediction model, simliar to what you did in (7.). Again also include a ROC curve (now of course for all 3 possible labels).\n",
    "- Is the performance comparable, better, worse than the pneumonia/no pneumonia case?\n",
    "- Which label can be predicted with the highest precision?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f30c402b",
   "metadata": {},
   "source": [
    "### 10. Possible improvements\n",
    "Try two possible strategies to improve the results you got on 8. and 9.\n",
    "- Data augmentation.\n",
    "- Model fine tuning. This refers to the training of a large network with lower learning rate, but with more layers of the base model being set to `trainable`.\n",
    "We haven't done this before, so here some example code of how to \"unfreeze\" some layers and make them trainable again:\n",
    "```python\n",
    "# Now: unfreeze some of the base model layers and do a second pass of training\n",
    "for layer in model.layers[:100]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[100:]:\n",
    "    layer.trainable = True\n",
    "``` \n",
    "You can still use the `Adam` optimizer, but preferably with a much lower learning rate, maybe `1e-5`.\n",
    "- Do you see any promising effect of one or both of those strategies?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc5554fa",
   "metadata": {},
   "source": [
    "## Final submission:\n",
    "Please address all the above mentioned points in this notebook (e.g., using text cells where needed for explanations or answers). Obviously, you can use code snippets from notebooks we have already worked on during the live coding sessions.\n",
    "\n",
    "\n",
    "### Happy hacking!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
