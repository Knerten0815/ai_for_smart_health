{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß†üí° Intelligent Systems  for Smart Health üë®‚Äç‚öïüë©‚Äç‚öïÔ∏èüî¨üå°Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Models Using Tree-based Models\n",
    "\n",
    "In a first step, we used linear models (Linear regression, logistic regression). Here we will explore another basic type of **machine learning** models: **tree-based models**!\n",
    "\n",
    "We will work with actual medical data in this notebook, namely the NHANES I epidemiology dataset (for a detailed description of this dataset you can check the [CDC Website](https://wwwn.cdc.gov/nchs/nhanes/nhefs/default.aspx/)).\n",
    "\n",
    "The key aim here is to predict the 10-year risk of death of individuals from the study. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1. Import Packages](#1)\n",
    "- [2. The Dataset](#2)\n",
    "    - [Exercise 1](#ex1)\n",
    "- [3. Handle missing data](#3)\n",
    "- [4. Decision Trees](#4)\n",
    "    - [Exercise 2 - hyperparmaters](#ex2)\n",
    "- [5. Random Forests](#5)\n",
    "    - [Exercise 3 - hyperparameter optimization](#ex-3)\n",
    "- [6. Systematic hyperparameter search](#6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6k2pItifWeK"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1. Import Packages\n",
    "\n",
    "We'll first import all the common packages that we need for this assignment. \n",
    "\n",
    "- `sklearn` is one of the most popular machine learning libraries.\n",
    "- `itertools` allows us to conveniently manipulate iterable objects such as lists.\n",
    "- `pydotplus` is used together with `IPython.display.Image` to visualize graph structures such as decision trees.\n",
    "- `numpy` is a fundamental package for scientific computing in Python.\n",
    "- `pandas` is what we'll use to manipulate our data.\n",
    "- `seaborn` is a plotting library which has some convenient functions for visualizing missing data.\n",
    "- `matplotlib` is a plotting library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe some missing libraries\n",
    "#!pip install pydotplus\n",
    "#!pip install lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5s0iQ82okBv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import itertools\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image \n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2. The Dataset\n",
    "### Load and explore the data!\n",
    "\n",
    "In virtually all cases, we would first want to get an intuition on the data itself. Things like: What is in the data? How much data is there? Are there things missing? What might cause problems? Do we understand the type of data/features?\n",
    "\n",
    "With **pandas**, we usually can explore some key properties very rapidly, for instance with commands like\n",
    "\n",
    "- `data.head()`\n",
    "- `data.describe()`\n",
    "- `data.info()`\n",
    "\n",
    "### Some weird conventions:\n",
    "For some reason it became standard in the machine learning world to name the actual data `X` and the labels `y`. Even though I consider this a rather poor choice both from a math and from a code best practice point of view, we will stick to this in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"../data/\"  # add your own path\n",
    "\n",
    "X = pd.read_csv(os.path.join(path_data, \"NHANESI_subset_X.csv\"))\n",
    "y = pd.read_csv(os.path.join(path_data, \"NHANESI_subset_y.csv\"))\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex1'></a>\n",
    "## Exercise 1:\n",
    "\n",
    "Answer the following questions:\n",
    "- How many features do we have?\n",
    "- How many datapoints do we have?\n",
    "- What is our label?\n",
    "- Do we have missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the \"unnamed\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3. Handle missing data\n",
    "\n",
    "Whenever we face missing data (incomplete entries, NaNs etc.), we have to decide how to deal with this. In general there are the following options:\n",
    "\n",
    "1. Ignore (usually a very poor choice... **unless**: we decide to deal with it later!)\n",
    "2. Remove incomplete entries --> Rows (fast and clean, but we loose datapoints)\n",
    "3. Remove incomplete entries --> Columns/Features (fast and clean, but we loose potentially important features)\n",
    "4. Replace missing entries --> replace by what? Average values, zeros, best guesses...? Can be an option, but needs a good understanding of the data and the process!\n",
    "\n",
    "#### Filling and dropping with pandas\n",
    "We can remove NaNs with pandas using `data.dropna()`. Or we can fill NaN entries using `data.fillna()`. Important here is to specify along which `axis` this operation should be done (rows or columns?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks good... or maybe not?\n",
    "\n",
    "- Now we have no incomplete entries in the data. But something went **VERY** wrong here. What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label is not fully understandable without further information\n",
    "\n",
    "For now let's simply say that all values > 0 mean: person died after x years.\n",
    "Negative values mean that those people haven't died as long as they participated (which was -years).\n",
    "In the following we aim to predict if people died after >= 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 10  # we focus on >10 year risk\n",
    "\n",
    "data[\"death\"] = np.ones(len(data))\n",
    "\n",
    "# remove all people which haven't died within the study\n",
    "data.loc[data[\"time\"] < 0, \"death\"] = 0\n",
    "\n",
    "# remove data which we can (and should) not use for predicting >10 year risk\n",
    "mask = (data[\"time\"] > 0) | (data[\"time\"] <= -threshold)\n",
    "data = data[mask]\n",
    "\n",
    "# Create data/label split --> X, y\n",
    "X = data.drop([\"death\", \"time\"], axis='columns')\n",
    "y = (data.time < threshold) & (data.time > 0)  # died within 0 and threshold years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect again data (X) and labels (y)\n",
    "- how much data have we left?\n",
    "- how are the labels distributed?\n",
    "- how is the \"Age\" and \"Race\" distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test split\n",
    "### --> For now: ignore biases\n",
    "\n",
    "Ways to better take care of those include:\n",
    "- random sampling with weights\n",
    "- model training with weights\n",
    "- over- or under-sampling\n",
    "\n",
    "### Train / Validation / Test\n",
    "\n",
    "We already discussed spliting the data into a **training set** and a **test set**. Often, however, we want to have 2 different test sets. One which is the \"real\" test set and remains untouched and is reserved for the model evaluation. And one set which we use to optimize our model parameters. The second one is typically called **validation set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first split --> get test set\n",
    "X_dev, X_test, y_dev, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second split --> train / validation\n",
    "X_train, X_val, y_train, y_val = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0OwPz5xh-uS"
   },
   "source": [
    "Use the next cell to look at an individual case get familiar with the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "mms5-w98ykxM",
    "outputId": "485fe24d-947c-4ae0-aaa9-63ef3f1eb318"
   },
   "outputs": [],
   "source": [
    "i = 3\n",
    "print(X_train.iloc[i,:])\n",
    "print(\"\\nDied within 10 years? {}\".format(y_train.loc[y_train.index[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4. Training a decision tree model\n",
    "\n",
    "Scikit-learn provides numerous differnt machine learning models and tools. This is very convenient to use, in particular because many elements of scikit-learn can be used in (more or less) the same way. \n",
    "\n",
    "For more details, please look at the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "The model we will use first in this notebook is a **decision tree classifier** (`DecisionTreeClassifier()`). The training of a model is again simply done by running `model.fit()`.\n",
    "\n",
    "- Please train such a decision tree using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=10)\n",
    "# train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two types of predictions\n",
    "- final predicition / classification\n",
    "- \"probability\" (not a real probability, but still...)\n",
    "\n",
    "#### 1. Use the model to make a prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we can also access the output one step before the final \"decision\". For some models this will give us float values (\"probabilites\"... kind of). Here, because we use one single decision tree we will only get 1 or 0 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Do the same but using `.predict_proba)\n",
    "What do you get from this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute a confusion matrix using the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check again on the validation set (X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative evaluation metric: concordance\n",
    "\n",
    "We can also use concordance, or the C-Index for evaluation.\n",
    "\n",
    "The C-Index evaluates the ability of a model to differentiate between different classes, by quantifying how often, when considering all pairs of patients (A, B), the model says that patient A has a higher risk score than patient B when, in the observed data, patient A actually died and patient B actually lived. In our case, our model is a binary classifier, where each risk score is either 1 (the model predicts that the patient will die) or 0 (the patient will live).\n",
    "\n",
    "More formally, defining _permissible pairs_ of patients as pairs where the outcomes are different, _concordant pairs_ as permissible pairs where the patient that died had a higher risk score (i.e. our model predicted 1 for the patient that died and 0 for the one that lived), and _ties_ as permissible pairs where the risk scores were equal (i.e. our model predicted 1 for both patients or 0 for both patients), the C-Index is equal to:\n",
    "\n",
    "$$\\text{C-Index} = \\frac{\\#\\text{concordant pairs} + 0.5\\times \\#\\text{ties}}{\\#\\text{permissible pairs}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lifelines\n",
    "\n",
    "def cindex(y_true, scores):\n",
    "    return lifelines.utils.concordance_index(y_true, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How good are the prediction according to the c-index?\n",
    "y_train_preds = tree.predict_proba(X_train)[:, 1]\n",
    "print(f\"Train C-Index: {cindex(y_train.values, y_train_preds)}\")\n",
    "\n",
    "y_val_preds = tree.predict_proba(X_val)[:, 1]\n",
    "print(f\"Val C-Index: {cindex(y_val.values, y_val_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - decision tree hyperparameters\n",
    "\n",
    "Try and find a set of hyperparameters that improves the generalization to the validation set and recompute the C-index. If you do it right, you should get C-index above 0.6 for the validation set. \n",
    "\n",
    "You can refer to the documentation for the sklearn [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=...)\n",
    "# train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the results\n",
    "y_train_preds = tree.predict_proba(X_train)[:, 1]\n",
    "print(f\"Train C-Index: {cindex(y_train.values, y_train_preds)}\")\n",
    "\n",
    "y_val_preds = tree.predict_proba(X_val)[:, 1]\n",
    "print(f\"Val C-Index: {cindex(y_val.values, y_val_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the trained decision tree\n",
    "One of the biggest advantages of a **decision tree** model is that we can intuitively understand and inspect how it comes to its predictions.\n",
    "\n",
    "We can, for instance, output the learned tree to see how decisions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7), dpi=300)\n",
    "plot_tree(tree, \n",
    "          feature_names=X_train.columns,  \n",
    "          class_names=['neg', 'pos'],\n",
    "          filled=True)\n",
    "\n",
    "#plt.savefig(\"decision_tree.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "-gc0vttU7Dkf",
    "CFM27SfS1QSD"
   ],
   "include_colab_link": true,
   "name": "C2_W2_Assignment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
