{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bd8fa0",
   "metadata": {},
   "source": [
    "# Ocular Disease Recognition --> tricks and multi-class predictions\n",
    "## CNN (Convolutional Neural Networks)\n",
    "\n",
    "Convolutional Neural Networks, or CNNs for short, are a powerful type of neural network commonly used in computer vision tasks. They are particularly well-suited to tasks like image classification and object detection because they are able to automatically learn and extract relevant features from input images. CNNs consist of multiple layers, each of which performs a different type of processing on the input data. These layers typically include convolutional layers, which extract features from the input images, and pooling layers, which downsample the output of the convolutional layers. By stacking these layers on top of one another, a CNN is able to learn increasingly complex representations of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b011721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdf2b0",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "\n",
    "\n",
    "Ocular Disease Intelligent Recognition (ODIR) is a structured ophthalmic database of 5,000 patients with age, color fundus photographs from left and right eyes and doctors' diagnostic keywords from doctors.\n",
    "\n",
    "This dataset is meant to represent ‘‘real-life’’ set of patient information collected by Shanggong Medical Technology Co., Ltd. from different hospitals/medical centers in China. In these institutions, fundus images are captured by various cameras in the market, such as Canon, Zeiss and Kowa, resulting into varied image resolutions.\n",
    "\n",
    "Annotations were labeled by trained human readers with quality control management. They classify patient into eight labels including:\n",
    "\n",
    "* Normal (N),\n",
    "* Diabetes (D),\n",
    "* Glaucoma (G),\n",
    "* Cataract (C),\n",
    "* Age related Macular Degeneration (A),\n",
    "* Hypertension (H),\n",
    "* Pathological Myopia (M),\n",
    "* Other diseases/abnormalities (O)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_dict = {\n",
    "    \"N\": \"Normal\",\n",
    "    \"D\": \"Diabetes\",\n",
    "    \"G\": \"Glaucoma\",\n",
    "    \"C\": \"Cataract\",\n",
    "    \"A\": \"Age related Macular Degeneration\",\n",
    "    \"H\": \"Hypertension\",\n",
    "    \"M\": \"Pathological Myopia\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868acdc9",
   "metadata": {},
   "source": [
    "## 1. Exploration\n",
    "\n",
    "Read the data from `csv` files.\n",
    "\n",
    "- What are medically useful labels to train a deep learning network on?\n",
    "- Are there any biases we need to consider?\n",
    "- Do we have to worry about \"data leakage\", something that often comes from having many datapoints for the same patients ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = \"../../../Data/ocular_disease_recognition/\"\n",
    "\n",
    "metadata = pd.read_csv(os.path.join(path_data, \"metadata.csv\"))\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d619158",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfcccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = ['N', 'D', 'G', 'C', 'A', 'H', 'M', 'O']\n",
    "metadata[label_column].sum(axis=1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06dccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[label_column].sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f29644",
   "metadata": {},
   "source": [
    "## Have a look at some of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3c0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = \"../../../Data/ocular_disease_recognition/preprocessed_images\"\n",
    "\n",
    "# Pick 9 random images\n",
    "np.random.seed(1)\n",
    "random_images = np.random.choice(metadata.filename, 9)\n",
    "\n",
    "# Adjust the size of your images\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Iterate and plot random images\n",
    "for i, filename in enumerate(random_images):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    img = plt.imread(os.path.join(path_images, filename))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "# Adjust subplot parameters to give specified padding\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f16d417",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d80274",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(metadata, test_size=0.15,\n",
    "                                     random_state=0\n",
    "                                    )\n",
    "print(f\"Training set size: {train_df.shape}\")\n",
    "print(f\"Test set size: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second split\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.15,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "print(f\"Training set size: {train_df.shape}\")\n",
    "print(f\"Validation set size: {val_df.shape}\")\n",
    "print(f\"Test set size: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19092dd7",
   "metadata": {},
   "source": [
    "## Data generators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efa9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Normalize images\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255\n",
    ")\n",
    "\n",
    "# Pick your label column(s)\n",
    "label_column = # add the label-columns we want to predict\n",
    "\n",
    "# Define the data generators\n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=path_images,\n",
    "    x_col=\"filename\",\n",
    "    y_col=label_column,\n",
    "    target_size=(320, 320),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=#add color mode\n",
    ")\n",
    "\n",
    "val_generator = image_generator.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=path_images,\n",
    "    x_col=\"filename\",\n",
    "    y_col=label_column,\n",
    "    target_size=(320, 320),\n",
    "    batch_size=32,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=#add color mode,\n",
    "    shuffle=False,  # this is crucial for later evaluation!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05265146",
   "metadata": {},
   "source": [
    "## Let's build a CNN and train it\n",
    "- last time we used a simple CNN we designed from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9821abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Define the input shape\n",
    "inputs = Input(shape=(320, 320, 3))\n",
    "\n",
    "# Define the CNN architecture\n",
    "x = Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(#add code here, activation=#add code here)(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=\"accuracy\") #metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, (ax1, ax2) = plt.subplots(2, figsize=(6, 10))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax1.plot(history.history['accuracy'], \"o--\")\n",
    "ax1.plot(history.history['val_accuracy'], \"o--\")\n",
    "ax1.set_title('model accuracy')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "ax2.plot(history.history['loss'], \"o--\")\n",
    "ax2.plot(history.history['val_loss'], \"o--\")\n",
    "ax2.set_title('model loss')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72852047",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0665186",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(val_generator)\n",
    "y_true = val_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for multi-class model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Compute the ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "classes = label_column\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Get class names\n",
    "class_names = list(classes)\n",
    "\n",
    "for i, label in enumerate(classes):\n",
    "    ax.plot(fpr[i], tpr[i],\n",
    "            label=f\"ROC curve -> {class_name_dict[label]} (area = {roc_auc[i]:.2f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver Operating Characteristic')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b6eb9",
   "metadata": {},
   "source": [
    "## Use transfer learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the DenseNet121 model but exclude the top layer (classification layer)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(320, 320, 3))\n",
    "\n",
    "# Add your own top layer for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# complete code here\n",
    "\n",
    "# Create the actual model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed437d",
   "metadata": {},
   "source": [
    "### Account for biases in the data by custom-made loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584adc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "class_weights = train_df[label_column].sum(axis=0)\n",
    "class_weights = class_weights.sum() / class_weights \n",
    "\n",
    "# Ensure class weights sum up to 1\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "def weighted_binary_crossentropy(class_weights):\n",
    "    class_weights = tf.constant([class_weights[k] for k in sorted(class_weights.keys())], dtype=tf.float32)  # ensure class_weights is float32\n",
    "\n",
    "    def _weighted_binary_crossentropy(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)  # ensure y_true is float32\n",
    "        y_pred = tf.cast(y_pred, tf.float32)  # ensure y_pred is float32\n",
    "        crossentropy = binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = tf.reduce_sum(class_weights * y_true, axis=-1)\n",
    "        weighted_loss = weight_vector * crossentropy\n",
    "        return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "    return _weighted_binary_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b24f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "metrics = [\n",
    "    'accuracy',\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              #loss='binary_crossentropy',\n",
    "              loss=weighted_binary_crossentropy(class_weights),\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a966c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, (ax1, ax2) = plt.subplots(2, figsize=(6, 10))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax1.plot(history.history['accuracy'], \"o--\")\n",
    "ax1.plot(history.history['val_accuracy'], \"o--\")\n",
    "ax1.set_title('model accuracy')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "ax2.plot(history.history['loss'], \"o--\")\n",
    "ax2.plot(history.history['val_loss'], \"o--\")\n",
    "ax2.set_title('model loss')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eeff3d",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = val_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for multi-class model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Compute the ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "classes = label_column\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Get class names\n",
    "class_names = list(classes)\n",
    "\n",
    "for i, label in enumerate(classes):\n",
    "    ax.plot(fpr[i], tpr[i],\n",
    "            label=f\"ROC curve -> {class_name_dict[label]} (area = {roc_auc[i]:.2f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver Operating Characteristic')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69d821",
   "metadata": {},
   "source": [
    "## Improve further....\n",
    "- Longer training\n",
    "- Lower learning rate (maybe)\n",
    "- add data augmentation to image generator (slight rotation and zoom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05c5e9",
   "metadata": {},
   "source": [
    "## Another option: fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6192110",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Our model has {len(model.layers)} layers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81303b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now: unfreeze some of the base model layers and do a second pass of training\n",
    "for layer in model.layers[:300]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[300:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# We use a smaller learning rate for fine-tuning\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              #loss='binary_crossentropy',\n",
    "              loss=weighted_binary_crossentropy(class_weights),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    validation_data=val_generator,\n",
    "    class_weight=class_weights,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, (ax1, ax2) = plt.subplots(2, figsize=(6, 10))\n",
    "\n",
    "# summarize history for accuracy\n",
    "ax1.plot(history.history['accuracy'], \"o--\")\n",
    "ax1.plot(history.history['val_accuracy'], \"o--\")\n",
    "ax1.set_title('model accuracy')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "ax2.plot(history.history['loss'], \"o--\")\n",
    "ax2.plot(history.history['val_loss'], \"o--\")\n",
    "ax2.set_title('model loss')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f29a19",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa90f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4fee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = val_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510ab51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for multi-class model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Compute the ROC curve and AUC for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "classes = label_column\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curve\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Get class names\n",
    "class_names = list(classes)\n",
    "\n",
    "for i, label in enumerate(classes):\n",
    "    ax.plot(fpr[i], tpr[i],\n",
    "            label=f\"ROC curve -> {class_name_dict[label]} (area = {roc_auc[i]:.2f})\")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver Operating Characteristic')\n",
    "ax.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2e416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
